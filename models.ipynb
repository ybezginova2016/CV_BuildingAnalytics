{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Задачи сегментации фасадов и детекции объектов (окна, колонны)\n",
    "\n",
    "#### Необходимо обучить собственный алгоритм tensorflow сегментации фасада главного здания, а также алгоритм определения числа окон и числа колонн.\n",
    "#### Заказчик хотел бы выделять на фото фасад \"главного\" здания, если на изображении несколько зданий.\n",
    "\n",
    "Решение задачи требует создания нескольких алгоритмов машинного обучения для решения трех различных задач:\n",
    "\n",
    "* Сегментация фасада главного здания на изображении\n",
    "* Определение числа окон на фасаде\n",
    "* Определение числа колонн на фасаде\n",
    "\n",
    "Для решения каждой из этих задач можно использовать различные алгоритмы машинного обучения, такие как нейронные сети и алгоритмы компьютерного зрения.\n",
    "\n",
    "Например, для **сегментации фасада главного здания на изображении можно использовать алгоритмы семантической сегментации**, такие как FCN, U-Net или SegNet, которые могут обучаться на размеченных данных, где каждый пиксель на изображении помечен как принадлежащий к фасаду или нет.\n",
    "\n",
    "Для **определения числа окон и числа колонн на фасаде можно использовать алгоритмы детектирования объектов**, такие как Faster R-CNN, RetinaNet или YOLO, которые могут обучаться на размеченных данных, где каждый объект (окно или колонна) на изображении помечен с помощью ограничивающей рамки.\n",
    "\n",
    "Также можно использовать готовые модели машинного обучения, предварительно обученные на больших наборах данных, такие как ImageNet, и дообучать их на своих размеченных данных.\n",
    "\n",
    "Однако, чтобы создать алгоритмы машинного обучения для решения этих задач, необходимо иметь доступ к размеченным данным, то есть набору изображений, на которых фасады главного здания помечены, а также размечены окна и колонны. Такие данные были получены на первом этапе предобработки данных путем ручной разметки изображений.\n",
    "\n",
    "Кроме того, необходимо провести оценку качества полученных моделей машинного обучения на тестовых данных, чтобы убедиться в их эффективности и точности. Для этого можно использовать метрики, такие как точность, полноту и F1-меру, а также визуально сравнить результаты работы модели с оригинальными изображениями.\n",
    "\n",
    "Кроме того, стоит учитывать, что **задача определения числа окон и колонн на фасаде может быть достаточно сложной, особенно если на изображении находятся объекты разных размеров, расположенные на разном расстоянии от камеры, в разных условиях освещения и т.д. Поэтому для получения точных результатов может потребоваться использование дополнительных методов предобработки изображений, таких как поворот, масштабирование и улучшение контрастности.**\n",
    "\n",
    "*Для обучения моделей используем U-Net и YOLO, так как работаем без GPU-ускорителя и ограничены домашним ноутбуком и мощностями Google Colab.*\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Сегментация фасадов с помощью U-Net\n",
    "\n",
    "**U-Net - это нейронная сеть для семантической сегментации изображений, разработанная для медицинских изображений, но также успешно применяемая для сегментации фасадов зданий.**\n",
    "\n",
    "Для проведения сегментации фасадов с помощью U-Net необходимо иметь размеченный набор данных, на котором обучится модель. Разметка данных представляет собой пометку каждого пикселя на изображении как принадлежащего к фасаду или не принадлежащего. Этот процесс может быть трудоемким и затратным.\n",
    "\n",
    "#### Обучение модели включает в себя:\n",
    "\n",
    "1. Нормализацию и предобработку данных, таких как изменение размера изображений, масштабирование значений пикселей и т.д.\n",
    "2. Разбиение данных на обучающую, валидационную и тестовую выборки.\n",
    "3. Определение архитектуры модели и настройка параметров, таких как количество слоев и фильтров, функция активации, оптимизатор и т.д.\n",
    "4. Обучение модели на обучающей выборке с использованием алгоритма обратного распространения ошибки и минимизации функции потерь.\n",
    "5. Оценка модели на валидационной выборке и настройка параметров модели для улучшения ее качества.\n",
    "6. Тестирование модели на тестовой выборке для оценки ее точности и эффективности.\n",
    "\n",
    "После того, как модель обучена, мы можем использовать ее для сегментации фасадов на новых изображениях. Для этого необходимо применить модель к каждому пикселю изображения и определить, принадлежит ли он фасаду или нет. Результаты сегментации могут быть сохранены в виде маски, где каждый пиксель помечен как принадлежащий фасаду или нет"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from  tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.models import load_model\n",
    "from matplotlib.pyplot import imsave,imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "import random\n",
    "from scipy import ndarray\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, concatenate, Concatenate, UpSampling2D, Activation\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, inception_resnet_block, conv2d_bn\n",
    "from keras.applications.densenet import DenseNet121, dense_block, transition_block\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "outputs": [
    {
     "data": {
      "text/plain": "        filename  background  facade  window  door  cornice  sill  balcony  \\\n0  cmp_b0001.png           0       1       1     1        1     1        1   \n1  cmp_b0002.png           1       0       1     1        1     1        1   \n2  cmp_b0003.png           1       1       0     1        1     1        1   \n3  cmp_b0004.png           1       1       1     0        1     1        1   \n4  cmp_b0005.png           1       1       1     1        0     1        1   \n\n   blind  deco  molding  pillar  shop  \n0      1     1        1       1     1  \n1      1     1        1       1     1  \n2      1     1        1       1     1  \n3      1     1        1       1     1  \n4      1     1        1       1     1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>background</th>\n      <th>facade</th>\n      <th>window</th>\n      <th>door</th>\n      <th>cornice</th>\n      <th>sill</th>\n      <th>balcony</th>\n      <th>blind</th>\n      <th>deco</th>\n      <th>molding</th>\n      <th>pillar</th>\n      <th>shop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cmp_b0001.png</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cmp_b0002.png</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cmp_b0003.png</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cmp_b0004.png</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cmp_b0005.png</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_png = pd.read_csv(\"C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\CV_BuildingAnalytics\\\\labels_png.csv\")\n",
    "label_png.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "outputs": [
    {
     "data": {
      "text/plain": "        filename  facade\n0  cmp_b0001.png       1\n1  cmp_b0002.png       0\n2  cmp_b0003.png       1\n3  cmp_b0004.png       1\n4  cmp_b0005.png       1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>facade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cmp_b0001.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cmp_b0002.png</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cmp_b0003.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cmp_b0004.png</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cmp_b0005.png</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_facade = label_png[['filename', 'facade']].copy()\n",
    "labels_facade.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "outputs": [],
   "source": [
    "labels_facade.to_csv('labels_facade.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "outputs": [
    {
     "data": {
      "text/plain": "          filename  background  facade  window  door  cornice  sill  balcony  \\\n0    cmp_b0001.jpg           0       1       1     1        1     1        1   \n1    cmp_b0001.png           0       1       1     1        1     1        1   \n2    cmp_b0002.jpg           1       0       1     1        1     1        1   \n3    cmp_b0002.png           1       0       1     1        1     1        1   \n4    cmp_b0003.jpg           1       1       0     1        1     1        1   \n..             ...         ...     ...     ...   ...      ...   ...      ...   \n751  cmp_b0376.png           1       1       0     1        1     0        0   \n752  cmp_b0377.jpg           1       1       0     1        1     1        0   \n753  cmp_b0377.png           1       1       0     1        1     1        0   \n754  cmp_b0378.jpg           1       1       0     1        1     1        0   \n755  cmp_b0378.png           1       1       0     1        1     1        0   \n\n     blind  deco  molding  pillar  shop  \n0        1     1        1       1     1  \n1        1     1        1       1     1  \n2        1     1        1       1     1  \n3        1     1        1       1     1  \n4        1     1        1       1     1  \n..     ...   ...      ...     ...   ...  \n751      1     1        1       1     1  \n752      1     1        1       1     1  \n753      1     1        1       1     1  \n754      0     1        1       1     1  \n755      0     1        1       1     1  \n\n[756 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>background</th>\n      <th>facade</th>\n      <th>window</th>\n      <th>door</th>\n      <th>cornice</th>\n      <th>sill</th>\n      <th>balcony</th>\n      <th>blind</th>\n      <th>deco</th>\n      <th>molding</th>\n      <th>pillar</th>\n      <th>shop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cmp_b0001.jpg</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cmp_b0001.png</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cmp_b0002.jpg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cmp_b0002.png</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cmp_b0003.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>751</th>\n      <td>cmp_b0376.png</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>752</th>\n      <td>cmp_b0377.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>753</th>\n      <td>cmp_b0377.png</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>754</th>\n      <td>cmp_b0378.jpg</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>755</th>\n      <td>cmp_b0378.png</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>756 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the path to the directory containing the image data and the CSV file with labels\n",
    "data_dir = \"C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\CV_BuildingAnalytics\\\\\"\n",
    "labels_file = \"C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\CV_BuildingAnalytics\\\\labels.csv\"\n",
    "\n",
    "labels_df = pd.read_csv(os.path.join(data_dir, labels_file))\n",
    "labels_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "outputs": [],
   "source": [
    "# split the data into training and validation sets\n",
    "train_size = 0.6  # Proportion of data to use for training\n",
    "val_size = 0.4  # Proportion of data to use for validation\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=12345)\n",
    "train_indices, val_indices = next(sss.split(X=labels_df['filename'], y=labels_df['facade']))\n",
    "\n",
    "train_df = labels_df.iloc[train_indices]\n",
    "val_df = labels_df.iloc[val_indices]\n",
    "\n",
    "# Create subdirectories for the subsets\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'valid')\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# Copy the image files to the subdirectories\n",
    "for _, row in train_df.iterrows():\n",
    "    src_path = os.path.join(data_dir, 'base', row['filename'])\n",
    "    dst_path = os.path.join(train_dir, row['filename'])\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "for _, row in val_df.iterrows():\n",
    "    src_path = os.path.join(data_dir, 'base', row['filename'])\n",
    "    dst_path = os.path.join(val_dir, row['filename'])\n",
    "    shutil.copy(src_path, dst_path)\n",
    "\n",
    "# Save the labels for the subsets to separate CSV files\n",
    "train_df.to_csv(os.path.join(data_dir, 'train_labels.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(data_dir, 'valid_labels.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "outputs": [],
   "source": [
    "# class_names = list(train_generator.class_indices.keys())\n",
    "# print('Названия классов из читаемой папки:', class_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "outputs": [],
   "source": [
    "MAIN_DIR = \"C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\CV_BuildingAnalytics\\\\\"\n",
    "\n",
    "TRAIN_DIR = \"C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\CV_BuildingAnalytics\\\\train\"\n",
    "VALID_DIR = \"C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\CV_BuildingAnalytics\\valid\"\n",
    "\n",
    "TRAIN_LABELS = \"C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\CV_BuildingAnalytics\\\\train_labels.csv\"\n",
    "VALID_LABELS = \"C:\\\\Users\\\\HOME\\\\PycharmProjects\\\\CV_BuildingAnalytics\\\\valid_labels.csv\"\n",
    "\n",
    "INPUT_SHAPE = (128, 128, 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "outputs": [],
   "source": [
    "def load_train(path):\n",
    "    labels = pd.read_csv(path + 'train_labels.csv')\n",
    "    labels['facade'] = labels['facade'].astype(str) # Convert facade column to string type\n",
    "    train_datagen = ImageDataGenerator(validation_split=0.25, horizontal_flip=True, rescale=1./255)\n",
    "    X_train = train_datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory=path + '\\\\train',\n",
    "        x_col='filename',\n",
    "        y_col='facade',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=16,\n",
    "        class_mode='binary',\n",
    "        subset='training',\n",
    "        seed=12345)\n",
    "\n",
    "    # Modify the labels to have shape (batch_size, 128, 128, 1)\n",
    "    y_train = np.expand_dims(X_train.labels, axis=-1)\n",
    "    y_train = np.tile(y_train, (1, 128, 128, 1))\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "def load_valid(path):\n",
    "    labels = pd.read_csv(path + 'valid_labels.csv')\n",
    "    labels['facade'] = labels['facade'].astype(str) # Convert facade column to string type\n",
    "    test_datagen = ImageDataGenerator(validation_split=0.25, rescale=1./255)\n",
    "    X_valid = test_datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory=path + '\\\\valid',\n",
    "        x_col='filename',\n",
    "        y_col='facade',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=16,\n",
    "        class_mode='binary',\n",
    "        subset='validation',\n",
    "        seed=12345)\n",
    "\n",
    "    # Modify the labels to have shape (batch_size, 128, 128, 1)\n",
    "    y_valid = np.expand_dims(X_valid.labels, axis=-1)\n",
    "    y_valid = np.tile(y_valid, (1, 128, 128, 1))\n",
    "\n",
    "    return X_valid, y_valid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "outputs": [],
   "source": [
    "# def dice_coefficient_loss(y_true, y_pred):\n",
    "#     axis = (1, 2)\n",
    "#     numerator = 2.0 * tf.reduce_sum(y_true * y_pred, axis=axis)\n",
    "#     denominator = tf.reduce_sum(y_true + y_pred, axis=axis)\n",
    "#     return 1.0 - tf.reduce_mean(numerator / denominator)\n",
    "\n",
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - (dice_coefficient(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "\n",
    "    inputs = tf.keras.layers.Input(input_shape)\n",
    "    s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "    conv1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(s)\n",
    "    conv1 = tf.keras.layers.Dropout(0.1)(conv1)\n",
    "    conv1 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(pool1)\n",
    "    conv2 = tf.keras.layers.Dropout(0.1)(conv2)\n",
    "    conv2 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(pool2)\n",
    "    conv3 = tf.keras.layers.Dropout(0.2)(conv3)\n",
    "    conv3 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(conv3)\n",
    "    pool3 = tf.keras.layers.MaxPooling2D((2, 2))(conv3)\n",
    "\n",
    "    conv4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(pool3)\n",
    "    conv4 = tf.keras.layers.Dropout(0.2)(conv4)\n",
    "    conv4 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(conv4)\n",
    "    pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(pool4)\n",
    "    conv5 = tf.keras.layers.Dropout(0.3)(conv5)\n",
    "    conv5 = tf.keras.layers.Conv2D(256, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(conv5)\n",
    "\n",
    "    upconv6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "    upconv6 = tf.keras.layers.concatenate([upconv6, conv4])\n",
    "    conv6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(upconv6)\n",
    "    conv6 = tf.keras.layers.Dropout(0.2)(conv6)\n",
    "    conv6 = tf.keras.layers.Conv2D(128, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(conv6)\n",
    "\n",
    "    upconv7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "    upconv7 = tf.keras.layers.concatenate([upconv7, conv3])\n",
    "    conv7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(upconv7)\n",
    "    conv7 = tf.keras.layers.Dropout(0.2)(conv7)\n",
    "    conv7 = tf.keras.layers.Conv2D(64, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(conv7)\n",
    "\n",
    "    upconv8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "    upconv8 = tf.keras.layers.concatenate([upconv8, conv2])\n",
    "    conv8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(upconv8)\n",
    "    conv8 = tf.keras.layers.Dropout(0.1)(conv8)\n",
    "    conv8 = tf.keras.layers.Conv2D(32, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(conv8)\n",
    "\n",
    "    upconv9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "    upconv9 = tf.keras.layers.concatenate([upconv9, conv1], axis=3)\n",
    "    conv9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(upconv9)\n",
    "    conv9 = tf.keras.layers.Dropout(0.1)(conv9)\n",
    "    conv9 = tf.keras.layers.Conv2D(16, (3, 3), activation=tf.keras.activations.elu, kernel_initializer='he_normal',\n",
    "                                padding='same')(conv9)\n",
    "\n",
    "    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "\n",
    "    model.compile(optimizer, loss='binary_crossentropy', metrics=[dice_coefficient,'accuracy'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "outputs": [],
   "source": [
    "def train_model(model,\n",
    "                X_train, y_train,\n",
    "                X_valid, y_valid,\n",
    "                batch_size=None,\n",
    "                epochs=5,\n",
    "                steps_per_epoch=None,\n",
    "                validation_steps=None):\n",
    "\n",
    "    if steps_per_epoch is None:\n",
    "        steps_per_epoch = int(np.ceil(X_train.samples / batch_size))\n",
    "    if validation_steps is None:\n",
    "        validation_steps = int(np.ceil(X_valid.samples / batch_size))\n",
    "\n",
    "    train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=batch_size)\n",
    "    valid_generator = ImageDataGenerator().flow(X_valid, y_valid, batch_size=batch_size)\n",
    "\n",
    "    callbacks = [EarlyStopping(patience=6, monitor='loss')]\n",
    "\n",
    "    model.fit_generator(train_generator,\n",
    "                        validation_data=valid_generator,\n",
    "                        epochs=epochs,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        validation_steps=validation_steps,\n",
    "                        verbose=2,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 340 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_train(MAIN_DIR)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "X_valid, y_valid = load_valid(MAIN_DIR)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "outputs": [
    {
     "data": {
      "text/plain": "<keras.engine.functional.Functional at 0x2c825ffa5e0>"
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_net = create_model(INPUT_SHAPE)\n",
    "u_net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = train_model(u_net, X_train, y_train, X_valid, y_train, batch_size=16, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "outputs": [],
   "source": [
    "def create_model2(input_shape, weights='imagenet'):\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # Contracting path (encoder)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "\n",
    "    # Expanding path (decoder)\n",
    "    up4 = Conv2DTranspose(128, 2, strides=(2, 2), activation='relu', padding='same')(conv3)\n",
    "    merge4 = concatenate([conv2, up4], axis=3)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(merge4)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "\n",
    "    up5 = Conv2DTranspose(64, 2, strides=(2, 2), activation='relu', padding='same')(conv4)\n",
    "    merge5 = concatenate([conv1, up5], axis=3)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(merge5)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv5)\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy',\n",
    "                  metrics=[dice_coefficient,'accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.save('facade_segmentation_v2.h5')\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "outputs": [],
   "source": [
    "def train_model(model, train_data, valid_data, batch_size=None, epochs=5,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "\n",
    "    if steps_per_epoch is None:\n",
    "        steps_per_epoch = len(train_data)\n",
    "    if validation_steps is None:\n",
    "        validation_steps = len(test_data)\n",
    "\n",
    "    callbacks = [EarlyStopping(patience=6, monitor='val_loss')]\n",
    "\n",
    "    model.fit(train_data,\n",
    "              validation_data=valid_data,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2,\n",
    "              callbacks=callbacks)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_47\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_64 (InputLayer)          [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_766 (Conv2D)            (None, 128, 128, 64  1792        ['input_64[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_767 (Conv2D)            (None, 128, 128, 64  36928       ['conv2d_766[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_170 (MaxPooling2  (None, 64, 64, 64)  0           ['conv2d_767[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_768 (Conv2D)            (None, 64, 64, 128)  73856       ['max_pooling2d_170[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_769 (Conv2D)            (None, 64, 64, 128)  147584      ['conv2d_768[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_171 (MaxPooling2  (None, 32, 32, 128)  0          ['conv2d_769[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_770 (Conv2D)            (None, 32, 32, 256)  295168      ['max_pooling2d_171[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_771 (Conv2D)            (None, 32, 32, 256)  590080      ['conv2d_770[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_134 (Conv2DTr  (None, 64, 64, 128)  131200     ['conv2d_771[0][0]']             \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_138 (Concatenate)  (None, 64, 64, 256)  0           ['conv2d_769[0][0]',             \n",
      "                                                                  'conv2d_transpose_134[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_772 (Conv2D)            (None, 64, 64, 128)  295040      ['concatenate_138[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_773 (Conv2D)            (None, 64, 64, 128)  147584      ['conv2d_772[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_135 (Conv2DTr  (None, 128, 128, 64  32832      ['conv2d_773[0][0]']             \n",
      " anspose)                       )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_139 (Concatenate)  (None, 128, 128, 12  0           ['conv2d_767[0][0]',             \n",
      "                                8)                                'conv2d_transpose_135[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_774 (Conv2D)            (None, 128, 128, 64  73792       ['concatenate_139[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_775 (Conv2D)            (None, 128, 128, 64  36928       ['conv2d_774[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_776 (Conv2D)            (None, 128, 128, 1)  65          ['conv2d_775[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,862,849\n",
      "Trainable params: 1,862,849\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = create_model2((128, 128, 3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 2176, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 5680, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 128, 128, 1) vs (None,)).\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[388], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m u_net1  \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m16\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[384], line 11\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(model, train_data, test_data, batch_size, epochs, steps_per_epoch, validation_steps)\u001B[0m\n\u001B[0;32m      7\u001B[0m     validation_steps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(test_data)\n\u001B[0;32m      9\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m [EarlyStopping(patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m6\u001B[39m, monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n\u001B[1;32m---> 11\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m          \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m          \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m          \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m          \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m          \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file8xyh45jo.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\losses.py\", line 2176, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\HOME\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\backend.py\", line 5680, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 128, 128, 1) vs (None,)).\n"
     ]
    }
   ],
   "source": [
    "u_net1  = train_model(model2, train_data, test_data, batch_size=16, epochs=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[235], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Manually calculate dice coefficient\u001B[39;00m\n\u001B[0;32m      2\u001B[0m dice_coefficients \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[43mhistory\u001B[49m\u001B[38;5;241m.\u001B[39mhistory[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m])):\n\u001B[0;32m      4\u001B[0m     dice_coeff \u001B[38;5;241m=\u001B[39m dice_coefficient(K\u001B[38;5;241m.\u001B[39mconstant(test_data[i][\u001B[38;5;241m1\u001B[39m]), K\u001B[38;5;241m.\u001B[39mconstant(u_net\u001B[38;5;241m.\u001B[39mpredict(test_data[i][\u001B[38;5;241m0\u001B[39m])))\n\u001B[0;32m      5\u001B[0m     dice_coefficients\u001B[38;5;241m.\u001B[39mappend(dice_coeff)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manually calculate dice coefficient\n",
    "dice_coefficients = []\n",
    "for i in range(len(history.history['loss'])):\n",
    "    dice_coeff = dice_coefficient(K.constant(test_data[i][1]), K.constant(u_net.predict(test_data[i][0])))\n",
    "    dice_coefficients.append(dice_coeff)\n",
    "print('Dice coefficient:', np.mean(dice_coefficients))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
